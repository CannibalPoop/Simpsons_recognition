{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"{\n \"cells\": [\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"Xw7YkEefehWo\"\n   },\n   \"source\": [\n    \"# Домашнее задание. Классификация изображений\",\n    \"\",\n    \"Сегодня вам предстоить помочь телекомпании FOX в обработке их контента. Как вы знаете, сериал \\\"Симпсоны\\\" идет на телеэкранах более 25 лет, и за это время скопилось очень много видеоматериала. Персоонажи менялись вместе с изменяющимися графическими технологиями, и Гомер Симпсон-2018 не очень похож на Гомера Симпсона-1989. В этом задании вам необходимо классифицировать персонажей, проживающих в Спрингфилде. Думаю, нет смысла представлять каждого из них в отдельности.\",\n    \"\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"oG47vhLxKNln\"\n   },\n   \"source\": [\n    \"### Установка зависимостей\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\"\n    },\n    \"id\": \"WWgcwKwCLBfr\",\n    \"outputId\": \"8d4c2f07-4cdb-409e-c5c7-1ddc6c1f1591\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"# we will verify that GPU is enabled for this notebook\",\n    \"# following should print: CUDA is available!  Training on GPU ...\",\n    \"#\",\n    \"# if it prints otherwise, then you need to enable GPU:\",\n    \"# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\",\n    \"\",\n    \"import torch\",\n    \"import numpy as np\",\n    \"import torchvision.transforms as transforms\",\n    \"import PIL\",\n    \"\",\n    \"import pickle\",\n    \"import numpy as np\",\n    \"from skimage import io\",\n    \"\",\n    \"from tqdm import tqdm, tqdm_notebook\",\n    \"from PIL import Image\",\n    \"from pathlib import Path\",\n    \"\",\n    \"from torchvision import transforms\",\n    \"from multiprocessing.pool import ThreadPool\",\n    \"from sklearn.preprocessing import LabelEncoder\",\n    \"from sklearn.model_selection import train_test_split\",\n    \"from torch.utils.data import Dataset, DataLoader\",\n    \"import torch.nn as nn\",\n    \"\",\n    \"from matplotlib import colors, pyplot as plt\",\n    \"%matplotlib inline\",\n    \"\",\n    \"# в sklearn не все гладко, чтобы в colab удобно выводить картинки\",\n    \"# мы будем игнорировать warnings\",\n    \"import warnings\",\n    \"warnings.filterwarnings(action='ignore', category=DeprecationWarning)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\"\n    },\n    \"id\": \"xA3o2xC3MlMI\",\n    \"outputId\": \"cbadb50a-9819-40b7-b52d-eba23329d79d\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"# from google.colab import drive\",\n    \"# drive.mount('/content/gdrive/')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"sxZ5llqziJ8k\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"# !unzip -q /content/gdrive/MyDrive/journey-springfield.zip\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Аугментация изображений для тренировочного и тестового датасетов\",\n    \"transform_train = transforms.Compose([\",\n    \"    transforms.ToTensor(),\",\n    \"    transforms.RandomHorizontalFlip(0.3),\",\n    \"    transforms.RandomVerticalFlip(0.3),\",\n    \"    transforms.RandomRotation(20),\",\n    \"    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 3)),\",\n    \"    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\",\n    \"])\",\n    \"\",\n    \"transform_test = transforms.Compose([\",\n    \"    transforms.ToTensor(),\",\n    \"    transforms.Normalize(\",\n    \"        (0.485, 0.456, 0.406), \",\n    \"        (0.229, 0.224, 0.225)),\",\n    \"])\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\"\n    },\n    \"id\": \"WTdzMtgJP15N\",\n    \"outputId\": \"9e09ac5b-d349-433c-f101-9a135a12e99a\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"# разные режимы датасета\",\n    \"DATA_MODES = ['train', 'val', 'test']\",\n    \"# все изображения будут масштабированы к размеру 224x224 px\",\n    \"RESCALE_SIZE = 224\",\n    \"# работаем на видеокарте\",\n    \"\",\n    \"train_on_gpu = torch.cuda.is_available()\",\n    \"\",\n    \"if not train_on_gpu:\",\n    \"    print('CUDA is not available.  Training on CPU ...')\",\n    \"    DEVICE = torch.device(\\\"cpu\\\")\",\n    \"else:\",\n    \"    print('CUDA is available!  Training on GPU ...')\",\n    \"    DEVICE = torch.device(\\\"cuda\\\")\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"8ecnkB2xK1aE\"\n   },\n   \"source\": [\n    \"Ниже мы исспользуем враппер над датасетом для удобной работы. Вам стоит понимать, что происходит с LabelEncoder и  с torch.Transformation.\",\n    \"\",\n    \"ToTensor конвертирует  PIL Image с параметрами в диапазоне [0, 255] (как все пиксели) в FloatTensor размера (C x H x W) [0,1] , затем производится масштабирование:\",\n    \"$input = \\\\frac{input - \\\\mu}{\\\\text{standard deviation}} $, <br>       константы - средние и дисперсии по каналам на основе ImageNet\",\n    \"\",\n    \"\",\n    \"Стоит также отметить, что мы переопределяем метод __getitem__ для удобства работы с данной структурой данных.\",\n    \" Также используется LabelEncoder для преобразования строковых меток классов в id и обратно. В описании датасета указано, что картинки разного размера, так как брались напрямую с видео, поэтому следуем привести их к одному размер (это делает метод  _prepare_sample)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"cj32U5iTQUe4\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"class SimpsonsDataset(Dataset):\",\n    \"    \\\"\\\"\\\"\",\n    \"    Датасет с картинками, который паралельно подгружает их из папок\",\n    \"    производит скалирование и превращение в торчевые тензоры\",\n    \"    \\\"\\\"\\\"\",\n    \"    def __init__(self, files, mode, transform=transform_test):\",\n    \"        super().__init__()\",\n    \"        # список файлов для загрузки\",\n    \"        self.files = sorted(files)\",\n    \"        # режим работы\",\n    \"        self.mode = mode\",\n    \"\",\n    \"        if self.mode not in DATA_MODES:\",\n    \"            print(f\\\"{self.mode} is not correct; correct modes: {DATA_MODES}\\\")\",\n    \"            raise NameError\",\n    \"\",\n    \"        self.transform = transform\",\n    \"        \",\n    \"        self.len_ = len(self.files)\",\n    \"\",\n    \"        self.label_encoder = LabelEncoder()\",\n    \"\",\n    \"        if self.mode != 'test':\",\n    \"            self.labels = [path.parent.name for path in self.files]\",\n    \"            self.label_encoder.fit(self.labels)\",\n    \"\",\n    \"            with open('label_encoder.pkl', 'wb') as le_dump_file:\",\n    \"                  pickle.dump(self.label_encoder, le_dump_file)\",\n    \"\",\n    \"    def __len__(self):\",\n    \"        return self.len_\",\n    \"\",\n    \"    def load_sample(self, file):\",\n    \"        image = Image.open(file)\",\n    \"        image.load()\",\n    \"        return image\",\n    \"\",\n    \"    def __getitem__(self, index):\",\n    \"        x = self.load_sample(self.files[index])\",\n    \"        x = self._prepare_sample(x)\",\n    \"        x = np.array(x / 255, dtype='float32')\",\n    \"        x = self.transform(x)\",\n    \"        if self.mode == 'test':\",\n    \"            return x\",\n    \"        else:\",\n    \"            label = self.labels[index]\",\n    \"            label_id = self.label_encoder.transform([label])\",\n    \"            y = label_id.item()\",\n    \"            return x, y\",\n    \"\",\n    \"    def _prepare_sample(self, image):\",\n    \"        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\",\n    \"        return np.array(image)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"j_odtTEzcaWH\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"def imshow(inp, title=None, plt_ax=plt, default=False):\",\n    \"    \\\"\\\"\\\"Imshow для тензоров\\\"\\\"\\\"\",\n    \"    inp = inp.numpy().transpose((1, 2, 0))\",\n    \"    mean = np.array([0.485, 0.456, 0.406])\",\n    \"    std = np.array([0.229, 0.224, 0.225])\",\n    \"    inp = std * inp + mean\",\n    \"    inp = np.clip(inp, 0, 1)\",\n    \"    plt_ax.imshow(inp)\",\n    \"    if title is not None:\",\n    \"        plt_ax.set_title(title)\",\n    \"    plt_ax.grid(False)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"QXyvJfT5jY-A\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"#определим директории с тренировочными и тестовыми файлами\",\n    \"TRAIN_DIR = Path('./train')\",\n    \"TEST_DIR = Path('./testset')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"yUhzOq1zRJil\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\",\n    \"test_files = sorted(list(TEST_DIR.rglob('*.jpg')))\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"TmPhhKKlRyCF\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"train_val_labels = [path.parent.name for path in train_val_files]\",\n    \"train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\\\",\n    \"                                          stratify=train_val_labels)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"aAimOLjSQGTh\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"val_dataset = SimpsonsDataset(val_files, mode='val', transform=transform_test)\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"PmKSdyv1b7PD\"\n   },\n   \"source\": [\n    \"Давайте посмотрим на наших героев внутри датасета.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\",\n     \"height\": 699\n    },\n    \"id\": \"ltitWp3lXAZt\",\n    \"outputId\": \"99d8d066-a9cf-420e-98fa-e4ac0d20086e\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\\\",\n    \"                        sharey=True, sharex=True)\",\n    \"for fig_x in ax.flatten():\",\n    \"    random_characters = int(np.random.uniform(0,1000))\",\n    \"    im_val, label = val_dataset[random_characters]\",\n    \"    img_label = \\\" \\\".join(map(lambda x: x.capitalize(),\\\\\",\n    \"                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\",\n    \"    imshow(im_val.data.cpu(), \\\\\",\n    \"          title=img_label,plt_ax=fig_x)\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"GpN9lSi4QVGt\"\n   },\n   \"source\": [\n    \"Можете добавить ваши любимые сцены и классифицировать их. (веселые результаты можно кидать в чат)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"e2mk7MNtcUhJ\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"def fit_epoch(model, train_loader, criterion, optimizer):\",\n    \"    running_loss = 0.0\",\n    \"    running_corrects = 0\",\n    \"    processed_data = 0\",\n    \"\",\n    \"    for inputs, labels in train_loader:\",\n    \"        inputs = inputs.to(DEVICE)\",\n    \"        labels = labels.to(DEVICE)\",\n    \"        optimizer.zero_grad()\",\n    \"\",\n    \"        outputs = model(inputs)\",\n    \"        loss = criterion(outputs, labels)\",\n    \"        loss.backward()\",\n    \"        optimizer.step()\",\n    \"        preds = torch.argmax(outputs, 1)\",\n    \"        running_loss += loss.item() * inputs.size(0)\",\n    \"        running_corrects += torch.sum(preds == labels.data)\",\n    \"        processed_data += inputs.size(0)\",\n    \"\",\n    \"    train_loss = running_loss / processed_data\",\n    \"    train_acc = running_corrects.cpu().numpy() / processed_data\",\n    \"    return train_loss, train_acc\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"w_CD9--hcUjs\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"def eval_epoch(model, val_loader, criterion):\",\n    \"    model.eval()\",\n    \"    running_loss = 0.0\",\n    \"    running_corrects = 0\",\n    \"    processed_size = 0\",\n    \"\",\n    \"    for inputs, labels in val_loader:\",\n    \"        inputs = inputs.to(DEVICE)\",\n    \"        labels = labels.to(DEVICE)\",\n    \"\",\n    \"        with torch.set_grad_enabled(False):\",\n    \"            outputs = model(inputs)\",\n    \"            loss = criterion(outputs, labels)\",\n    \"            preds = torch.argmax(outputs, 1)\",\n    \"\",\n    \"        running_loss += loss.item() * inputs.size(0)\",\n    \"        running_corrects += torch.sum(preds == labels.data)\",\n    \"        processed_size += inputs.size(0)\",\n    \"    val_loss = running_loss / processed_size\",\n    \"    val_acc = running_corrects.double() / processed_size\",\n    \"    return val_loss, val_acc\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"NaxYIwB3cUmX\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"def train(train_files, val_files, model, epochs, batch_size, optimizer):\",\n    \"    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\",\n    \"    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\",\n    \"\",\n    \"    history = []\",\n    \"    log_template = \\\"\\Epoch {ep:03d} train_loss: {t_loss:0.4f} \\\\\",\n    \"    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\\\"\",\n    \"\",\n    \"    with tqdm(desc=\\\"epoch\\\", total=epochs) as pbar_outer:\",\n    \"        criterion = nn.CrossEntropyLoss()\",\n    \"\",\n    \"        for epoch in range(epochs):\",\n    \"            train_loss, train_acc = fit_epoch(model, train_loader, criterion, optimizer)\",\n    \"            print(\\\"loss\\\", train_loss)\",\n    \"\",\n    \"            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\",\n    \"            history.append((train_loss, train_acc, val_loss, val_acc))\",\n    \"\",\n    \"            pbar_outer.update(1)\",\n    \"            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\\\",\n    \"                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\",\n    \"\",\n    \"    return history\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"v6G7qbYqcUpL\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"def predict(model, test_loader):\",\n    \"    with torch.no_grad():\",\n    \"        logits = []\",\n    \"\",\n    \"        for inputs in test_loader:\",\n    \"            inputs = inputs.to(DEVICE)\",\n    \"            model.eval()\",\n    \"            outputs = model(inputs).cpu()\",\n    \"            logits.append(outputs)\",\n    \"\",\n    \"    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\",\n    \"    return probs\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\"\n    },\n    \"id\": \"yzwhB4K3dQOC\",\n    \"outputId\": \"97d0a216-321d-44d3-d58b-8409eaeebdf5\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"from torchvision.models import resnet50, resnet18\",\n    \"\",\n    \"n_classes = len(np.unique(train_val_labels))\",\n    \"# Дообучим модель resnet18\",\n    \"model = resnet18(pretrained=True)\",\n    \"model.fc = nn.Sequential(\",\n    \"    nn.Linear(512, 256),\",\n    \"    nn.Dropout(),\",\n    \"    nn.ReLU(),\",\n    \"    nn.Linear(256, 128),\",\n    \"    nn.Dropout(),\",\n    \"    nn.ReLU(),\",\n    \"    nn.Linear(128, 64),\",\n    \"    nn.BatchNorm1d(64),\",\n    \"    nn.ReLU(),\",\n    \"    nn.Linear(64, 42),\",\n    \")\",\n    \"    \",\n    \"model.to(DEVICE)\",\n    \"print(model)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Заморозим первые 5 слоев сети, т.к. они выделяют низкоуровневые признаки, переобучение которых \",\n    \"# может ухудшить качество наших предсказаний\",\n    \"\",\n    \"counter = 0\",\n    \"\",\n    \"for child in model.children():\",\n    \"    counter += 1\",\n    \"    if counter < 5:\",\n    \"        for param in child.parameters():\",\n    \"            param.requires_grad = False\",\n    \"print(counter)\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"bo3UND5RdgVg\"\n   },\n   \"source\": [\n    \"Запустим обучение сети.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"WDkcxZ1kfD4a\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"if val_dataset is None:\",\n    \"    val_dataset = SimpsonsDataset(val_files, mode='val', transform=transform_test)\",\n    \"\",\n    \"train_dataset = SimpsonsDataset(train_files, mode='train', transform = transform_train)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"len(train_dataset)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\"\n    },\n    \"id\": \"iDXoR8PIdfLD\",\n    \"outputId\": \"aa45bc7b-7194-459b-e538-70b2726a3b56\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"history = train(train_dataset, val_dataset, model=model, epochs=20, batch_size=128, optimizer=optimizer)\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"7qMAdL_BduXZ\"\n   },\n   \"source\": [\n    \"Построим кривые обучения\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import gc\",\n    \"from torch import cuda\",\n    \"\",\n    \"clear_mem = False\",\n    \"\",\n    \"if clear_mem == True:\",\n    \"    gc.collect()\",\n    \"    torch.cuda.empty_cache()\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"2ryD_9yFdfNr\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"loss, acc, val_loss, val_acc = zip(*history)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\",\n     \"height\": 773\n    },\n    \"id\": \"GpQDWGkfdfQ5\",\n    \"outputId\": \"f16bc2e5-fe5e-468d-ea38-a46dfb939d8b\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"plt.figure(figsize=(15, 9))\",\n    \"plt.plot(loss, label=\\\"train_loss\\\")\",\n    \"plt.plot(val_loss, label=\\\"val_loss\\\")\",\n    \"plt.legend(loc='best')\",\n    \"plt.xlabel(\\\"epochs\\\")\",\n    \"plt.ylabel(\\\"loss\\\")\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\",\n     \"height\": 773\n    },\n    \"id\": \"pCs3gZoUvBBn\",\n    \"outputId\": \"451369c0-656a-4fad-ede2-9cd48bc0d8a6\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"plt.figure(figsize=(15, 9))\",\n    \"plt.plot(acc, label=\\\"train_acc\\\")\",\n    \"plt.plot([i.cpu().numpy() for i in val_acc], label=\\\"val_acc\\\")\",\n    \"plt.legend(loc='best')\",\n    \"plt.xlabel(\\\"epochs\\\")\",\n    \"plt.ylabel(\\\"acc\\\")\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"Gr9lRCJNNDfD\"\n   },\n   \"source\": [\n    \"### Ну и что теперь со всем этим делать?\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"DSe0nQ-dJ8uy\"\n   },\n   \"source\": [\n    \"![alt text](https://www.indiewire.com/wp-content/uploads/2014/08/the-simpsons.jpg)\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"y5k0UGeTNaQX\"\n   },\n   \"source\": [\n    \"Хорошо бы понять, как сделать сабмит.\",\n    \"У нас есть сеть и методы eval у нее, которые позволяют перевести сеть в режим предсказания. Стоит понимать, что у нашей модели на последнем слое стоит softmax, которые позволяет получить вектор вероятностей  того, что объект относится к тому или иному классу. Давайте воспользуемся этим.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"Z8PlF6o0N9O1\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"def predict_one_sample(model, inputs, device=DEVICE):\",\n    \"    \\\"\\\"\\\"Предсказание, для одной картинки\\\"\\\"\\\"\",\n    \"    with torch.no_grad():\",\n    \"        inputs = inputs.to(device)\",\n    \"        model.eval()\",\n    \"        logit = model(inputs).cpu()\",\n    \"        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\",\n    \"    return probs\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"pY_OoLoVO_9V\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"random_characters = int(np.random.uniform(0,1000))\",\n    \"ex_img, true_label = val_dataset[random_characters]\",\n    \"probs_im = predict_one_sample(model, ex_img.unsqueeze(0))\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"caivVFeAN9SY\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"idxs = list(map(int, np.random.uniform(0,1000, 20)))\",\n    \"imgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\",\n    \"\",\n    \"probs_ims = predict(model, imgs)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"t-0pRdHnQQKM\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"label_encoder = pickle.load(open(\\\"label_encoder.pkl\\\", 'rb'))\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"GNMFc7sfQh1a\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"y_pred = np.argmax(probs_ims,-1)\",\n    \"\",\n    \"actual_labels = [val_dataset[id][1] for id in idxs]\",\n    \"\",\n    \"preds_class = [label_encoder.classes_[i] for i in y_pred]\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"iVePL0-BKHrF\"\n   },\n   \"source\": [\n    \"Обратите внимание, что метрика, которую необходимо оптимизировать в конкурсе --- f1-score. Вычислим целевую метрику на валидационной выборке.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\"\n    },\n    \"id\": \"_h-9dDWsKGU-\",\n    \"outputId\": \"5baadcf0-f6a0-4a73-fd79-209045ad951e\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"from sklearn.metrics import f1_score\",\n    \"f1 = f1_score(actual_labels, y_pred, average='micro')\",\n    \"\",\n    \"print(\\\"F1-оценка:\\\", f1)\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"pxB9pfPfdCHr\"\n   },\n   \"source\": [\n    \"Сделаем классную визуализацию,  чтобы посмотреть насколько сеть уверена в своих ответах. Можете исспользовать это, чтобы отлаживать правильность вывода.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\",\n     \"height\": 1000\n    },\n    \"id\": \"VVjq4EC5ZZE7\",\n    \"outputId\": \"cbe55ddb-c72e-4f41-ea6c-bd99fd9937fc\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"import matplotlib.patches as patches\",\n    \"from matplotlib.font_manager import FontProperties\",\n    \"\",\n    \"fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\\\",\n    \"                        sharey=True, sharex=True)\",\n    \"for fig_x in ax.flatten():\",\n    \"    random_characters = int(np.random.uniform(0,1000))\",\n    \"    im_val, label = val_dataset[random_characters]\",\n    \"    img_label = \\\" \\\".join(map(lambda x: x.capitalize(),\\\\\",\n    \"                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\",\n    \"\",\n    \"\",\n    \"\",\n    \"    imshow(im_val.data.cpu(), \\\\\",\n    \"          title=img_label,plt_ax=fig_x)\",\n    \"\",\n    \"    actual_text = \\\"Actual : {}\\\".format(img_label)\",\n    \"\",\n    \"    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\",\n    \"    font0 = FontProperties()\",\n    \"    font = font0.copy()\",\n    \"    font.set_family(\\\"fantasy\\\")\",\n    \"    prob_pred = predict_one_sample(model, im_val.unsqueeze(0))\",\n    \"    predicted_proba = np.max(prob_pred)*100\",\n    \"    y_pred = np.argmax(prob_pred)\",\n    \"\",\n    \"    predicted_label = label_encoder.classes_[y_pred]\",\n    \"    predicted_label = predicted_label[:len(predicted_label)//2] + '\\' + predicted_label[len(predicted_label)//2:]\",\n    \"    predicted_text = \\\"{} : {:.0f}%\\\".format(predicted_label,predicted_proba)\",\n    \"\",\n    \"    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\",\n    \"                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"hO9OLOMqIXRV\"\n   },\n   \"source\": [\n    \"Попробуйте найти те классы, которые сеть не смогла расспознать. Изучите данную проблему, это понадобится в дальнейшем.\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"QEWTL6jgdh7L\"\n   },\n   \"source\": [\n    \"### Submit на Kaggle\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"wrjQ6cxHIGtk\"\n   },\n   \"source\": [\n    \"![alt text](https://i.redd.it/nuaphfioz0211.jpg)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"9UTbU0Zbc6Hb\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"test_dataset = SimpsonsDataset(test_files, mode=\\\"test\\\")\",\n    \"test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\",\n    \"probs = predict(model, test_loader)\",\n    \"\",\n    \"preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\",\n    \"test_filenames = [path.name for path in test_dataset.files]\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\"\n    },\n    \"id\": \"_rTtbV1teD2k\",\n    \"outputId\": \"2135cd45-a428-4924-a36a-13bc54855e3b\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"! ls\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\",\n     \"height\": 206\n    },\n    \"id\": \"yw0zZ-Hdd89s\",\n    \"outputId\": \"82351b06-f0e6-4fa6-9cb4-b6ec5d127764\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"import pandas as pd\",\n    \"my_submit = pd.read_csv(\\\"./sample_submission.csv\\\")\",\n    \"my_submit = pd.DataFrame({'Image_id': test_filenames, 'Expected': preds})\",\n    \"my_submit.head()\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"VIYaqa20iYTL\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"# TODO : сделайте сабмит (это важно, если Вы не справляетесь, но дошли до этой ячейки, то сообщите в чат и Вам помогут)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"5rdlyMKtiYe2\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"my_submit.to_csv('resnet18.csv', index=False)\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"h3M9SQZ7MuUq\"\n   },\n   \"source\": [\n    \"## Приключение?\",\n    \"\",\n    \"А теперь самое интересное, мы сделали простенькую сверточную сеть и смогли отправить сабмит, но получившийся скор нас явно не устраивает. Надо с этим что-то сделать.\",\n    \"\",\n    \"Несколько срочныйх улучшейни для нашей сети, которые наверняка пришли Вам в голову:\",\n    \"\",\n    \"\",\n    \"*   Учим дольше и изменяем гиперпараметры сети\",\n    \"*  learning rate, batch size, нормализация картинки и вот это всё\",\n    \"*   Кто же так строит нейронные сети? А где пулинги и батч нормы? Надо добавлять\",\n    \"*  Ну разве Адам наше все? [adamW](https://www.fast.ai/2018/07/02/adam-weight-decay/) для практика, [статейка для любителей](https://openreview.net/pdf?id=ryQu7f-RZ) (очень хороший анализ), [наши ](https://github.com/MichaelKonobeev/adashift/) эксперименты для заинтересованных.\",\n    \"\",\n    \"* Ну разве это deep learning? Вот ResNet и Inception, которые можно зафайнтьюнить под наши данные, вот это я понимаю (можно и обучить в колабе, а можно и [готовые](https://github.com/Cadene/pretrained-models.pytorch) скачать).\",\n    \"\",\n    \"* Данных не очень много, можно их аугументировать и  доучититься на новом датасете ( который уже будет состоять из, как  пример аугументации, перевернутых изображений)\",\n    \"\",\n    \"* Стоит подумать об ансамблях\",\n    \"\",\n    \"\",\n    \"Надеюсь, что у Вас получится!\",\n    \"\",\n    \"![alt text](https://pbs.twimg.com/profile_images/798904974986113024/adcQiVdV.jpg)\"\n   ]\n  },\n  {\n   \"attachments\": {},\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Kaggle Score\"\n   ]\n  },\n  {\n   \"attachments\": {\n    \"31a22949-a3a9-47d7-8b17-39f1e51b18df.png\": {\n     \"image/png\": \"iVBORw0KGgoAAAANSUhEUgAABe4AAABsCAYAAAAcwSKzAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAACgZSURBVHhe7d0NdFTlve/xHySEQAgEEkCSoIkpJoLyokbFBDSx9gK2SClgr4RasO2B1FMp9yC3mmDbxPYGWgoeD6S14LFAbTFFSFvhSCUqIGqgQkQNKiZgEgQTCISXkBe4e888k5nJCyQByWC/n7Vm5f88s2fvPXssXes3z/x3p8iBUecEAAAAAAAAAAB8QmfzFwAAAAAAAAAA+ACCewAAAAAAAAAAfAjBPQAAAAAAAAAAPqTFHvdRMTGmAgAAAAAAAAAA7VW8b5+z6NpdOnPKWZ8HN6cFAAAAAAAAAOAL5P9ckbMoL9G50o907p1XdHZrjlR7xjnfCK1yAAAAAAAAAAC4HMIi1WlYkjp/N1OdJ86RunQ1T3gjuAcAAAAAAAAA4DLrPO4H6pw4yYy8EdwDAAAAAAAAANABOo2421TeCO4BAAAAAAAAAOgAnSIGmcobwT0AAAAAAAAAAB0hLNIU3gjuAQAAAAAAAADwIQT3AAAAAAAAAAD4EIJ7AAAAAAAAAAB8CME9AAAAAAAAAAA+hOAeAAAAAAAAAAAfQnAPAAAAAAAAAIAPIbgHAAAAAAAAAMCHENwDAAAAAAAAAOBDCO4BAAAAAAAAAPAhBPcAAAAAAAAAAPgQgnsAAAAAAAAAAHwIwT0AAAAAAAAAAD6E4B4AAAAAAAAAAB9CcA8AAAAAAAAAgA8huAcAAAAAAAAAwIcQ3AMAAAAAAAAA4EMI7gEAAAAAAAAA8CEE9wAAAAAAAAAA+BCCewAAAAAAAAAAfAjBPQAAAAAAAAAAPoTgHgAAAAAAAAAAH9IpcmDUOVMDl134mHlKnxGvvo5RkV6aMlcrHLVLhMbMnK0pybGKHtBXXWs+V1lxkfI3LVPWnwrNNgAAAAAAAADgu/yfKzJVU3UPRpvK7coM7nv5qXOI948FzlXW6twxM4Bv+P5C5dzj/I/uk02T9OgzjtKI0OSMJUodF61gM2MH9+tvnqQMM9LAaVqyLFUJAwLMhLeK/KV6ZOZyEd8DAAAAAAAA8GVfzuC+VzcFTAxVt8F91DWsmzr5mfnG6utUX35c1e8f0um1x1VPkN+xnsjRjvHO/+iKc2/WpJ85Sss0LfhbqpJdgXyd9fC3C+/gfsby7Uod7tym5mCBtr5WqIqe4Yoflagok/YX58609pvvHAAAAAAAAACAD2prcO/TPe473RCm4IXD1e8/h6p3UoQC+58ntLf5+cuvfx8FJV2vsP+MV9jCa9T1Btr4+54oXWuH9nVVKsxJ0+J3qsy8p1QlXmeC/Yqtyvr6dD26MEtZ6Y9o0rQ1KrTDfkvUiPsU7iwBAAAAAAAA4EvBN1PtyJ7q/oub1O/RGHXv31WdzHTbdJZf/6sU8mi8+v4iQl0izbSvmZqtvJ07tcN65DyRqHkrX3XUO3bmKN1sIiVq9lM5ytvu3M7x2P6qcp6arQSzhVuExszJVu6rHttajzdeWq3Mb8eZbWzTtMy1zV/SFT4pUzmveLzmlRwt+L7n9i6tORezb7Pa3hY13rltzhNmoqJAq56YqpRfbjATjYWqZ3dnVXOoSOudpdOnZao6bWr/rtY7bp0Eu3XPK9vd52098uzrMqnxHlpzDSM074+u53K14DYz3cD7+cwmzwMAAAAAAABA83wuuO907zUKy7hewZFdzIy3c9W1qi05rNMfNnqUnFR99VmzlbfOkZHqkzFUwfc2v09fEXzbfE0e7O747pSo9L8sVEpCtII9W70HBCsqYZoW/iXdK7y/71fPKnNqvMLNbmpO1Tj+BvSP05i52Vr2nWZi7q7D9NT/GauoEDO2hUQreeYCLRhtxg5tO5eWrdCPHpquxRtLzbg5G1X4qbMKiBqm1IHO2mH0UEWY91fxyTa1plFOwhM5Wjgz2XqPniduXXP7uvxktdd1ad01LFXWDld3/QjFTYw3tTEwRTfGmPrTAq1/y9QAAAAAAAAAcAE+FNx3lt+sG9T3/qvk17gdTu1pVW//SOVz83X4B//UkceKdDyz0eOxPSr/gfX83D2q3H5EtbXmtS5+3dT9/uHqMyuonSv4v3ih/UNVtW+zVixMU9rCVdpszd33m/m6L8oOm2tUlpellJtv1i03T1VWXqk1Y4faEzTvSVdoPFuTR4U6y0NblTXhZt0xaqRu+fEaFZ6yJ4M1LDnF8bSXAdEKP7RZS9Ot46Yv1eZPnUG1HUjHPzDN1G05l5WadZf1XK67b5Pd4/4Wa3tnn/tSlZlQvmX5Slu0TsX2jrsP1Yw/vqxVT2VqQXaO8hYmO9vjVORr5cJ1dnV+45do/vhoOSL7qkKt/9lU61zGa9aSzSpzvNVgxc9Il/PKtOEaLtqsAsecFD5kijyj+/BvD1Wco2+/VLhtWau+XAAAAAAAAAAAm88E936zBitsZKNQvf60Tv+1QIdnFujYsiOqP9T8inpP5w6d1JllH+nIzHyV//Ww6uvNEw6d1WXkDeo9q5sZ+5i9azR1ylwt/dMGbfzTOm3TNI0ZYULkves08z/WyLnGu1Av/EeGNpvwOzw+RWMcVbACTVisyjJtc4Xjr2fp0TkzHUH7Hd/NMpMeThVqzb/P1YqXrOO+tFyP/vu6hh7ywX2jnEWbz+USeD1DacvWqbjSqruHKi5hrJLjoxVsvceag1u19PEMrbrgFwBSyrhhcp55jQpWT1VGrn3mpcr/w1xl/KNINZWlKiwslW60t2nLNVyurR+aLzkGxGpyQzucCE0bYVrq1BVqx8Lz/bIAAAAAAAAAALz5RHDvN/0GhY4MMiOnc+WlOpJeoOMvnNa5xqvnW6P2rOpfKFJ5+gc6We4d+NvhfZ/pvhfel+1bpTJTOwyMbWgJU+UfptSMTGU2PO5TcL0JjUMjzGrvHfrkkKOQYqco95Vc5SxfovSHpyjO2rOrsUsTFUVa4xmAe/aQd2nzuVysCKX85mWteGSCs4XPqQoV7yuyHqWqqpMCBiQqNdu7xU3zIhR3lTnxU4Xa8YyzdMlPn6Q77h6vlJkZWvWuPdO2a7hi/duqcFQe7XI82uTU7Nmsxc4SAAAAAAAAAFql44P7ERHqleS90v7s/iKVzytRbYmZuBglx3ViXoGO7TdLyB06q0tSjLqPMEMfUVPXaGX26DCZyFnBMckaM26s1yPB0bbG0wY9+v/WqNBeoW4LiVDU8ETdN32eFmTn6o2/ZWu2V896o/6M9xcGzWnzuVyk8Y9q2uhQR3ubmuJ1emTU1zRpyiTrMV5J05eqoMreKFjxsxZotmf/+yaSFerq3W+9z+OmbFkbr2Fungqdyb3CRzh/beBuk1OjwjeX2wUAAAAAAAAAtFrHBvdduiloRqQ8bxlrh/YVPz+ss+1ZZd+S2jOq/vmeRuF9kIKtY/v58v1qP66SI5+2VGxbrDRHD/rmHov1gtnObumScvfNSvnxUr3wj3wVFlc4VqjbAgbEK2VOZvtWxLfnXC7CmKTrG9rbFG7K0DZHbby/XGveMWl5wLUaeq+zbF6hqk6YsrXadA3XadU75guX0Ggl3+bRJqfiba1vtMIfAAAAAAAAAC6kQ4P7zg9cqx69zMBW/ZkqL3Vo7+II7z/S6WoztvWKUM8HfDi5f6tI5ebmp6Fh4Spw9KB3Pwo+L1exo97qbuEyMF7J356gqKLlypo3Uynf+pqSJqVps6v9y8C49vWgb8+5XITgrq4V/AEK6G5KD2Hd3M/3NK33m5ev4nLTxif4WsWPd5Yu4XOeVe5fVmtZ1mxNdq3cb+M1zF9bYH6xYLfLmdHQJqfivY1a7ywBAAAAAAAAnxJ3/eBL8sAXo+OC+y491WN0DzOwndHJ5/ar9osI7V1qj+v4cwfleb/agNGRCvDZ7H6p++ansWOVOWeswp0jafRsLViYrVU7d+qNv2Qq2Z6bnq28ddlaMDdd8x6f5t5WwY4bujqcqjI92duqjediKypvWKUfHJxoqtZ54Z0imaMp7t5nNXuMu5d93LcXasowV+OeUhX+w5RTFyp3y07t2JKrJR6975du2m3OI1QJD2drhvn3JHzMbGXeO1ThUXGKv2OYgu0+/+25hm8tU36xswwfMUoRju1Klf+nDY45AAAAAAAAwFckjr5Tz636o37yeNolefx68RJNmPgts3dcKh0W3HeaMEDdPALzcx8f0EmvfigXr9PXrGPc2ugtbitR1cceLXO69FP3CR3bMeh8Vvx0qfId/daDNXRqpnK3b9cbW7Zrx2+mKc6RXVdp9/pl2myXz67SNnOT2eD42Q3bvpEzT/FmVXrFjvVa6izbrE3nYssrUqm51KFJS7Rj507lZrWyUc8zaVqab2L/kKFKeTLX+V6279SquckKdyy4r1Fx7gKlveXYSimj4hVur87vHqH4Oz3WxK/O0HLXvkLjlbpyp2NfuU9O01BH/3trP/9YrhV22a5rWKrlb5rfGYSGWlfH8mmB1pvzAgAAAAAAAHzFNydONNWlERbWV6NGN3djTVyMTpEDo86Z+jLqom4Lb1LP/mZor7Z/epdOvG2Gl0Cn0Ver9/cGWEc6qRNPv6+Tb581z1hujVTYwxHyM0MdKtbncw/JY4vLZ2q28ubEO8Le4tybNelnzmkvg6co86epGhPjWmVuVBZp4zNpSvuTR3Oagda2v25m21MVKnz193o0fY1p6zJNy16drXjHgdfplm9lOGadzvNcW87FkvDIs5r/wFCFular712pWx5YbAZOKdmvarbjYEVaf/MkuY8WoTFz0pU6Pl7hjQ5XYx1vc6Pjhc9ZrZypcQqwg/i1P9KkJ/PNM7Y4Tc7IVOrXot0r522nSpX/4jJlLNrgvkFvq6+hp1St2PKQhpq2PoV/Gq+UhY1uNgwAAAAAAP4lxH17nmbdE6+4mAgFq0pln36i3ZuWa/kf8pvJFM4nTpMfn637brpWEf2C1bXmc5UV79Xm9cu1NLelZsURGjNzlu5LiNO1A93HL9y2XkuzPfIPI+XJ1ZowqKsZNadKu/97ujJeMkMjfMw8pc+IV18z/mTTJD3qda+/CMV/Z4Zm3DOsVeeBy8NubWOvkre9uPYvKvzgA0fdXmF9++r7P/g3R/3LJzOt/b3vqNGU/3NFpmqq7sFoU7l1THB/TX/1zoiSq0u5yg/o8zkHL1lw7g7tXRqH913UbdFN6hlmhjqh4+nv6fR+M/RVdu/1G8Mc163m8wJtzj9fMBynhHHRztXfJ4q08fWW/jFvpzadi3U2o8cqShdxHoMTNSbKfjdnVPHuZuWbVfGNhccnW+/c+j+wFs/H+j+Nrw5VqH3iF7wuX/A1BAAAAAAAXzJxmpH9lFJdP9tvpGbfOs2dkqFWNZ0YPVsr0qZpaLO7qlHF60s1/ccrvQPwgdO05LepSujfkLp5qTm0VUv/7RGt8shV0v+yU/dFmUGzqpS/6C7NWm2G9pcJv1qgHydFuLM9i/eC1ETN+2OmJsc2WhRp1By0zmOW93ng8vAM7i9F0H6p9/dldmUE9/fGqP/9Dam5arcX6Miy02Z0cZqG9pbqclWm79MZ181FLX6zhipsZDczkk7/+S0d/7sZAAAAAAAAAG2UkJWrJV9133dPNTWqqZMCursj7qr8xZo6s1Hg3sQELXk5XQmu0L6uRhUlparqFqGohlDebiE8V5N+ttWMIzT7jzlKiTXP11WpbH+5tVWAQq+JaOhAYH958MiUDDn7FIy1jpPpPk6zPIL721K1LH2a4gc0/WLAM7hPWfqqZt/mDu2rDhapQmGKGuCeq9m7UpMeWMzK+8uM4L7jtDW475Dm7n5XB5nKVqe6Dy9vaG+r//CYPL+x8L/aHeIDAAAAAAAAbTJwnmbd5Qrta1T8UprGjxypO0aNVEp2gczd9xQcP03zxptBS+ZMdofpNUVaP3ek/te3JmnSuJF6JLfI2rstQFFffUgzHLVthhJdob0qlL9wqsZPsV4zZbySntxqzTgFxAyT+86AYQpwvaQqX4tvvlm3NHl4rLb/ylDFmdC+at+GhvsEektV8o2ugL5K+Uus43/dOo+v36XxS/IbrkNAbKIeGmgGAJrokODev69nSH5GdQdN2Vj/rvJr6IN/fm0J7R0O1sjjFrXq4nVOAAAAAAAAQOuFz4hXnOu+ehVva2W6u4974TNp2rjXDBSqoeOmmbp5Kde5V+2XvZ6ljNfNwLLtZ1na6srSug9V8hxTe6r6RNtyPNoI5+7QJ67E3EuU+roy9spybTbledVVqGB1mqZOSVN5vZnzdFu0wsw9AFVVqG1/cJ9H2R/Wq8D1DYLCFM79TIEWdUhw7+206pv7BUX/nuo5f7jCMmLU9QLhfZtDe9v7Z9Tcvy0AAAAAAABAW02IdoftVR9v03pTO5Vq5T53gB18VazCTX0hNaecTW3c8lV1xpSWiK9MMdW7KnWF4sFxSviO+3zCv5OgOFdAX1GqAlN6qT+jnuNTtWB5jnLW5GhVdqZSx8eZJ42PN2vp3K9pxqLz3Fz2rbka71qtf9dMrTLTTtEKblg7e1wVHl9IAPDWAcF9Z3XyStib4Qjtr1c3+x+UwDCFnCe8b1do35wu1nmZEgAAAAAAAGiL0GB33/eKQ2tM5VZWWNbQJkYhYUo2ZXPKTzub4diiYud5h/y3pWtYpKltnbuaYp2yVm1VheOlwYr/4WrlrrFD+Fyt/mG8NWOpqdC2VQvcXypMjVBDR56QUVrxxENKHh6tqJhoxcWP1YwnVut/lk5zH/+tNXrhIsL2hKwxGupajV+cr/XcnBZoUQcE92d1rtaULegUGyJ/17eAthbC+0sW2ttqrfMyJQAAAAAAANBRNuZ90NCTXrFT9OzKdM0YN1ZjpmcqJ2uColwteRop+8MjemTJBhVWWgP/YIXH2CG8uTFtZZE2/+5HesSjdY38zF9LQEioAqoqVLyvSGX2643Q21L11OPxZtR+CU/kaKHrxr123/4lrhvkAmiOD7TK6Sa/waY0zr1+QEd/f1Be+X6j8P6iQ/vBXT3/bQIAAAAAAAB8Q+4Crcx3N6UPHTxBqRmZynx4rKKCq5Sf7xG+N4hQym9e1oq5YxUX4pypOlSk4kNmPyHRSn640Qr6vOXKSF+qF17arG0vLdb4u76mSVMmafzd47W44fgBirozxeOGtm3nCO3HR1t7slnnv+wRr779AJrqkOC+7vPTprJ1lf8AU3o4X3jf7RuXYKX9gAB5fjlZ63VOAAAAAAAAQBt43EwxoHszK9T7Bzvb1disbT3a1DejVKtmTlXa6nyVedxUtqaySBsXztTmsz3NjDV3utxZfD9TqaNDneF4jbXd4+OVNG6SJo27S+Mf36Bi033HXkGf+X1nrU/ztfml5cpKn6tH0ld69K23j79OhXVmGBqh9q25j9DkrFzv0D57pmZ5rvoH0KwOCe7rD5w0lc1f/tc13JXCS0vhfc/JF98ex++6Xl497esOENwDAAAAAACgffIb7gwrhQ9MbnLz2ZTr3DeL1aFCvWDKlpVq46KZGn+XudGr9bjj7klK+1OwhoW7vgKoUeneDY4q5WZXOC5V7V6vtI3ucLxsY5rW7XavoI9LSDX1+VSo6qLiMvsXAM/qx1+NcJ5XXYXyl0zVrGcKHc8COL+OaZWz54T1z4pbl0EhLZ5Is+G9p3b1tO+igEGeXxacUO0eUwIAAAAAAABt5N2XPkGzR5vaNjBVyUPcN3QsfMczto9Q/FeTFT/QDC3hT+Rox86dzsffFirBzNvCv/OQElzbnirU1mxTewjuGd7oi4MIRfR0Hz8gwBnxp2S/2nCc/3lqgmOuwdQExblecqrK/d5aJU4zsldb18D8AsAO7f9rOivtgTbomOB+/xFVewbtYf3V/VZTN6PF8L69N6K9tb+CwkxtO1SuM/tNDQAAAAAAALRV7iptLTa1IpSclatlj6cqde4S5ax8SEO7m6eq8rVxoSvAjlf6mhwty1qoZdbfdBP2l63YqkLXqtcByVr4t2e1wO5x/1SOVv8wvqHlTtkby7XC1Js/LHUvlI2doOxfTXN+GTAwXikZSzQm1vmUzfXFwaqdRQ2vCU2YrZxfpWryuLGa/PAS5T7sPk7Ve5u11NQXlqjZ/52t1Hj3FwUVe95WxaBZyrTfg8cjdbzZAEATHRPcq1bVb3vcnlpd1X1MH6/WNY01Ce/bG9pbb7nrmP5eN6Y98/bnOmtqAAAAAAAAoO3ylbFkXUMveQVEKH7iQ5rx7URFuTJse+X5igytMkNpjIbFmAY3AdEaluQs9eliLdvoDtUDBgxV8rixGpMQrWBz08aa4nXKmrfVObCULVqm9Xvd7XDCk2Zr2bqd2rEuW7PHWa8zz9TsW6dlri8OnknT0oab0AYrKukhzcvI1LzpiQp39d2pyNfyJ1eaQWskKfFGd2hvCx1unbt9/o0eySPMBgCa6KDgXjq37qBOeyyh7/SVqxXk+bufZjSE9+0O7S0JkQr+isdtaWsP69Q6YnsAAAAAAABcpNczNOmhLG3c53FHWaPmYL5WPdG4XUyedruS/poi7c5zlrZtP5ukGdmbVey59tVWV6Oy/JWa+60MbTNTTluV9cBUZeUUeN3QtkFVqQrWZmnGFM/X2TehnamslwpVccpMuZjjpD00U6s+NXMALptOkQOjzpn6suv84BD1vbuHGVmqP9ORH+5XbYsN7Q37zrQX2qY5XXqq539dr26BZmypeeWfOvpce3YGAAAAAAAAtCROCY6V7mdU8e5m5bcYfts97mOlvS1vEx6frKF9u1pVlYpf2qpW3d51cKLGmKX+VcUbtO19R3leDcepKVfBP/JVZubx5RF3/WD95PE0R/3LJzNV+EEr/sM4j0u9vy8z/+eKTNVU3YPRpnLr0OBeXbopaNFQ9ehlxpazB4t1JO2Q6i91lt6lqwLn36Be13istj9WqvI5JZf+WAAAAAAAAADgYwjuO05bg/sOa5XjUHtaJ1eUeC2e7zwgSn3m91Nne1X9pdJcaK+TqrKOTWgPAAAAAAAA4F9NWN++juD94h7Xm73hUuvYFfeG3/QbFJoU5HVz2nPlpTq6qES1JWaivSJ7qsecWAWFeX5HcVa1eXt05NnTZgwAAAAAAAAAX25hYX31k7Q0x99L7cGUB0yF5lxZK+6N+mf3qGL7STNy6hQWoT4ZQ9Vzcjd1as/q+y6d5Tc5WmEZ1zcK7aXa7YT2AAAAAAAAAP61lJd/rhfXrnX8vVTsfT3zu9+aES4Vn1hx79RZfrMGK3Sk98p7h9rTqt5RohNrK1V/6KyZbF6n/kEKmBiuoFv6qEuTwP+sare/r6PLTspH3jQAAAAAAAAAXFb2inu7Vc6lQF/71rmybk7bjE73XqPQSVfJz89MNHKuulZ15UdVd8pMuHQPUkBYN/kFtvAjgvrTOpXzgar+7ptN7f1j7tHkCaM0KMT04a+rVsn7L2ntiztUWeec6nhJmpZxj7TpMa183UxdkL8C+/dT4MnDqjxxed5I0E1TdP/Y4YoMdI6rD+1S7vNrVFjhHAMAAAAAAADA5XRFtsrxdO7v+1We/oGqSpoP2DsFdlGXyH7qdl2jR2RQi6H92ZISHUkv8NnQPmj0TM35bpIGntmrl3OW66mlq7V2V6lChkxU6owkBZntrkwxSvruw/rO2Bgz/oJdN1EPfXO4wip26Plnn9ZTz29SUeBwTZk+RZGe9yYGAAAAAAAAAB/lc8G9Q8lxnXrsnzq8YJ9OHTrTzrY2Z1V/6DNVLsjX54+VXvxNbr8o/iM1bvTV8v90k/7r6dV6c/c+VR58T3vWL9ei53fpxMAkTRwdbDZ2CVTQgHCF2I8ejdNoe4W7mQ/srehbR2lQhFl67nhuiG5IHK6wxq/r0U8h/e3jmNc3u++WtHQ+9nywulmVf9dg6/l+CvTa5fneR/vccMdwhZzYpT9mr9VHn5Sp8v08vfDsFh3sNVxfS3JdR+dxg+zL0uNqDUocqciG41vPXTtcI24d4ny+FfxDzXsY0Nu6es1r2CbU3qnzGjfd/6W/HgAAAAAAAACuPD7XKqdZvbopYGKoug3uo65h3dSphTY6qq9TfflxVb9/SKfXHlf9MTPvy0bP1Px7ArV58WJtbdLKJVwjvj1ecce26PkN7zmnQkdq8ve+oet7WHW99bCuxYkP/6rfrtwu5+19YzV23oMadPg9nYiIVZgdEneVDr65WrsG3K+xEVK1Pedfp482/UbPv37U8arIyT/RjGvLlF8Ro/hrpLp6f/n71eng26v1zF/3OrZptlVOw/nUqfqM81iV76/V8ud3WOfj3N79Q48q5a/8pTZ8aJXnfV17xWjsfzyk+OOb9PPf5Zk5m/OaxFds0M9/v8UaO8+ry973FBITa10N5/X44O9/1omEqYrvVq06/0Br9ojyn1+sDXtbaPHjH6vkmVOV2N9fdWesbbpaezpzQBuWZVvX0Wyj3rph2kxNvC7YuqjWNv7+qvxnnoquS1LI9uauo1U3+7kCAAAAAAAAuFK1tVWOX89eIT81te86U6f6Xcd1ZtMhnVxfqpObP9Pp7Z/pVN7BhsfJFw/oxJ+tetMR1ew6o3NnzGt9XOSt92hE0AHlbXpPx82cW5U+27NDez523eU5VmN/OEXDzu3Syl8/pfX/eEXbDofq5jvv1E0hJXrL0cQ9TIMShyumR5X+8dtFevF/XtNu/1jddXuCrjnxipYselavvvZPnRo0UrcNCta+bc7j9hwySiMGhivo8Dr97unV2rR5mz4MjFXC7fEKOfyaPnScQrSGJcdIn7yigv322Hk+Q05uUfaiZ7TpVef5xCcl6Tr/t/XOJ3tVkFei7rcOV1Dhc1rw9Dp97Ai0L/S6Gnujdjiq4MF3K7Z7mXa89bEaGiP5X6f45FiFnizWazuLrQnn+7im0wH9/tdLtSlvmw5cdYvuvt06z49XakH2Wm3Zap33TSMVP6DOvKapyPum696rj+nVVb/R6vWbtGVLiXredqdGRpzSll3On3gE3vM9fe+mrvpg/TIte/5vem3LR+py1zd1R2hnVTa6juf/XAEAAAAAAABcqTp/c7apmjq7bomp3HyzVc6FHKvX2f21Xo9zV8Lq+mYM6N24Dc55DLtdN/aqUn7uGhVVO6fq3lujtQVVChl8uwY5pxwq923VHkfeW6fK/Yd1wq9aH7+VZ1ZvH1V+YZnUo48GOMYuB7T9edfNcKt1cEOudlQG6sb4kY5nm3Ccz2G9/ucNKjeL0uveW6vNn9QpMjZRLXaaaffrpupHj/+HvjGs5TYy7xTsU13YSD1w33BnW54esUr8wVgN6uR83lPRP9ea41erqPSo5HdE/3zZ/Lqgbq/e3V8l9e6rSOdMEyUv/kq/yHxaW/e5Poy9eueTKvmHDTDXNVi3xIZLn76pF3Ycdsyo7oC2/nWXyp0jpzZ8rgAAAAAAAAC+/K7M4P5L5ODRKlO1Qq9uCtRRldutZjyUHDoqBXZTiBk3r1anT5uyJSeO6KAJ0p0OyD49/x4hzYfpjvPpp9Ez5+vRx12PxzTuan8pKFhhZrMm2vm6wH69FRLYR3372V3zW/D2c/rD20fU+5YpevSJX2j+vAd1a9Umvbzf6421oFpn2vQFUKDCho3VxO/N1o/s95D2C80YGiz5+dudbizhCg6SKo+WOUYNPj0qr0/9oj5XAAAAAAAAAF82BPcdrPz4aalHuKJ6mQkvwYq84x7FD+1nxh2krk5mIXgzjqjwze163fOxNU8vb9ntvaq8iba/rnrT0/p5+mNasel8X3bUqeSvi7XgZ7/UU0uf1lNZ87Vo5S75B/k3DdAvUuQ3f6zUSSN11ZkDevu1XK1cvlArC9rwRQwAAAAAAAAANIPgvoNVv7lbRXX9dOs3hpsZD7FjNXFskm7sb5bKf3ZEleqnq4Y4hy7REf2cq+XNuN2afIEwRFf1sc7xhKvHfiMVVTph/Tnx4Sa9+Yr7sWPXDu14Y2/LYX97X9cKN6TM16MPf0NhdVWqPFimyhN10sB7NLR/tYred91k91KI1Y3XBetEwWotXblWb27dpYMHqxTUw/PXAPtUflQKuXqI968Ibrrau0XRF/25AgAAAAAAALiiENx3tGN5Wpt3QIGxUzTne2M16NpwhQwIV/Toqfr+5OEKObZLL+eZVdwfvqk9FYEaMfZB3RBhN68JVNjtD+obgwNV/v6bct4O9WL00x1Tx2qAvWv/fopLGa8RQVV69+1dzqcbe2+LdlX00e33u87HX4HXjdV3Zs3Vj/63K4UuU9VJqUfo1QoJDJS/3Xe+Va9rnz0flsq/f7y+ed9wBQVa+x04UhPvv0Uhpdu1+T2z0SVR5mgj1CNiiPN6OT6LqUq+xrP/fp3yX9ulypBbNOPhqUpMHGV9dtbnek+M9Y49fOGfKwAAAAAAAIAriV/PXiE/NTU6SO3+XXq3qreih92mhPhbdZv1GBbTR/UHXtOK3/1VnzW0Zz+moo+Oqfv1I/XVu5J0Z/Kdir8uREcL1mnVix+o1rFNmAYlDlfo0d16633H3Wml0CG6bVgfHSnYqo/NlK65RXfGSB/n7ZDdQKbnkFEaEfSBNu0fpPvv/7ruvOt2Deldow82ZGv9btca+GgNS7Ze9MkrKthvjxufT5IShl2jzgfy9Ifn39Sps/Y2NTpwrJdGjEzQnXfeqcja16zXHm3F69qp9F190DlKt942Snfdae335lj1PLZdq363QRUN+238PiyNrofNcU16H9U7297TcTPnVqOSwwGKiR+ppKS7nZ9Fv0N6o6SbooM9XlPxnnYe6Kyrrr9eQwfFKKb3ab255l0F3BR9nuvY3OcKAAAAAAAA4ErV+ZuzTdXU2XVLTOXWKXJg1DlTwxf06KeQoNOqPHSBXun2dsFS9eeHVd2a+65eQOTkn2jGtfu0ImuNShz7rtWJg0fV6l0H9lZI726qPVqmk832uvFXYA9/VZ9o9OQFX9de1vH695PfsUu938acxwlUVcufmf0zgzrPK5mkaRn3SJse08rXzZTLJf5cAQAAAAAAAHQ8/+eKTNVU3YPRpnKjVY6vOXH4wqG9zd7u4BcU7jr23YbQ3lZ91NFTvuWQvK5paG+74OvayzreoS86tLc5j9PSZxZ010w9+n9nKjHG0U/HEqjoybcrWkd0qLn/rX6RnysAAAAAAACAKwLBPfAFOrn1Jb1xuI+Svztf8zN+YT3ma9oQ6aNX1+jlT81GAAAAAAAAAOCBVjnA5eBogWPfkvZ021oQAQAAAAAAALji0SoH8EWOFjhlbW9BBAAAAAAAAOBfDsE9AAAAAAAAAAA+hOAeAAAAAAAAAAAfQnAPAAAAAAAAAIAPIbgHAAAAAAAAAMCHENwDAAAAAAAAAOBDCO4BAAAAAAAAAPAhBPcAAAAAAAAAAPgQgnsAAAAAAAAAAHwIwT0AAAAAAAAAAD6E4B4AAAAAAAAAAB9CcA8AAAAAAAAAgA8huAcAAAAAAAAAwIcQ3AMAAAAAAAAA4EMI7gEAAAAAAAAA8CEE9wAAAAAAAAAA+BCCewAAAAAAAAAAfAjBPQAAAAAAAAAAPoTgHgAAAAAAAACAjlBeYgpvBPcAAAAAAAAAAHSAc6UfmcobwT0AAAAAAAAAAB3g3DuvmMobwT0AAAAAAAAAAJfZ2Zd+p7Nbc8zIG8E9AAAAAAAAAACXQ3mJzu3O09n/TtPZtYuk2jPmCW+dIgdGnTO1l6iYGFMBAAAAAAAAAID2Kt63z1St02JwDwAAAAAAAAAALj9a5QAAAAAAAAAA4DOk/w/F+cnlmVj9cwAAAABJRU5ErkJggg==\"\n    }\n   },\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"0ukcJl_g78nK\"\n   },\n   \"source\": [\n    \"![image.png](attachment:31a22949-a3a9-47d7-8b17-39f1e51b18df.png)\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"accelerator\": \"GPU\",\n  \"colab\": {\n   \"provenance\": []\n  },\n  \"kernelspec\": {\n   \"display_name\": \"Python 3 (ipykernel)\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.10.5\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}","metadata":{"_uuid":"9b22c103-b570-48a9-bce9-8aad2e37953e","_cell_guid":"992b459e-4198-4728-a05c-dc23419049b2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}